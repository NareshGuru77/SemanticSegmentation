{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "import time\n",
    "import tqdm\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import warnings\n",
    "np.seterr(all='raise')\n",
    "warnings.filterwarnings('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAugmentation():\n",
    "    \n",
    "    def __init__(self, label_def, IMAGE_DIMENSION=[480, 640], NUM_OF_SCALES=2, \n",
    "                     BACKGROUNDS_PATH ='./backgrounds/training/', IMAGE_PATH='./objects/image', \n",
    "                     LABEL_PATH='./objects/label', IMG_TYPE='.jpg',\n",
    "                     MIN_OBJ_AREA_PERCENT=20, MAX_OBJ_AREA_PERCENT=70):\n",
    "\n",
    "        self.label_def = label_def\n",
    "        self.image_dimension = IMAGE_DIMENSION\n",
    "        self.image_path = IMAGE_PATH\n",
    "        self.label_path = LABEL_PATH\n",
    "        self.img_type = IMG_TYPE\n",
    "        self.min_obj_area_percent = MIN_OBJ_AREA_PERCENT\n",
    "        self.max_obj_area_percent = MAX_OBJ_AREA_PERCENT\n",
    "        self.regenerate_augment_vector_count = 0\n",
    "        \n",
    "        files_count, object_paths = self.fetch_image_gt_paths()\n",
    "        \n",
    "        if NUM_OF_SCALES is 'RANDOMIZE':\n",
    "            self.num_of_scales = np.random.randint(1, 5, size= files_count)\n",
    "            self.num_objects = np.sum(self.num_of_scales)\n",
    "        else:\n",
    "            self.num_of_scales = NUM_OF_SCALES\n",
    "            self.num_objects = self.num_of_scales * files_count\n",
    "            \n",
    "        self.background_images = self.get_background_images(BACKGROUNDS_PATH)\n",
    "        self.objects = self.get_synthetic_objects_list(object_paths)\n",
    "        self.augment_vector = list()\n",
    "    \n",
    "    def fetch_image_gt_paths(self):\n",
    "        \"\"\"\n",
    "        This function counts the number of annotated images and\n",
    "        fetches the path of the images and corresponding labels..\n",
    "        \n",
    "        Returns the number of annotated images and a dictionary mapping\n",
    "        the object name to the corresponding image and label paths...\n",
    "        \"\"\"\n",
    "        object_paths = dict()\n",
    "        files_count = 0\n",
    "        for item in os.listdir(self.label_path):\n",
    "            cls_path = os.path.join(self.label_path, item)\n",
    "            if os.path.isdir(cls_path):\n",
    "                obj_files = list()\n",
    "                for files in sorted(os.listdir(cls_path)):\n",
    "                    files_count += 1\n",
    "                    obj_files.append([os.path.join(self.image_path, item, files.split('.')[0]+self.img_type), \n",
    "                             os.path.join(self.label_path, item, files)])\n",
    "                    object_paths[item] = obj_files.copy()\n",
    "            else:\n",
    "                files_count += 1\n",
    "                cls_name = '_'.join(item.split('_')[:-1])\n",
    "                if object_paths.get(cls_name, None) is None:\n",
    "                    object_paths[cls_name] = list()\n",
    "                object_paths[cls_name].append([os.path.join(self.image_path, item.split('.')[0]+self.img_type), \n",
    "                             os.path.join(self.label_path, item)])\n",
    "            \n",
    "        return files_count, object_paths\n",
    "    \n",
    "    def get_background_images(self, backgrounds_path):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function reads the background images and creates a list...\n",
    "        \"\"\"\n",
    "\n",
    "        background_files = os.listdir(backgrounds_path)\n",
    "        background_files = [os.path.join(backgrounds_path, file) for file in background_files]\n",
    "        background_images = list()\n",
    "        for file in background_files:\n",
    "            background_images.append(cv2.imread(file))\n",
    "            \n",
    "        return background_images\n",
    "    \n",
    "    def create_augment_vector(self, REMOVE_CLUTTER= True, NUM_OF_IMAGES= 50, MAX_OBJECTS_PER_IMAGE= 6, \n",
    "                              GENERATION_REATTEMPTS= 100, CLEAR_AUGMENT_VECTOR= True, \n",
    "                              MIN_DIST_BTW_LOCATIONS= 70, MAX_OCCUPIED_AREA= 0.8):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function creates a randomized augment vector, based on \n",
    "        which the images are augmented..\n",
    "        \n",
    "        # parameters which are randomized:\n",
    "            1. 'background_image': selects a random background image.\n",
    "                    It is also ensured that all backgrounds are selected once\n",
    "                    before randomizing again.\n",
    "                    \n",
    "            2. 'num_objects_to_place': number of objects to be placed in\n",
    "                    the image.\n",
    "            \n",
    "            3. 'what_objects': a list of random indices are created. Objects in\n",
    "                    the corresponding indices will be chosen for augmentation.\n",
    "                    \n",
    "            4. 'locations': randomized (x,y) in the pixel space for each object..\n",
    "        \"\"\"\n",
    "        \n",
    "        if CLEAR_AUGMENT_VECTOR:\n",
    "            self.augment_vector.clear()\n",
    "        \n",
    "        self.generation_reattempts = GENERATION_REATTEMPTS\n",
    "        self.min_dist_btw_locations = MIN_DIST_BTW_LOCATIONS\n",
    "        self.max_occupied_area = MAX_OCCUPIED_AREA\n",
    "        objects_index = np.arange(0, self.num_objects)\n",
    "\n",
    "        for i in range(NUM_OF_IMAGES):\n",
    "            num_objects_to_place = np.random.randint(1, high= MAX_OBJECTS_PER_IMAGE)\n",
    "            what_objects = [objects_index[i] for i in range(num_objects_to_place)]\n",
    "    \n",
    "            if i % len(self.background_images) == 0:\n",
    "                np.random.shuffle(self.background_images)\n",
    "        \n",
    "            #if i % num_objects == 0:\n",
    "            np.random.shuffle(objects_index)\n",
    "        \n",
    "            self.augment_vector.append({'background_image': self.background_images[\n",
    "                                                            i % len(self.background_images)], \n",
    "                       'num_objects_to_place': num_objects_to_place, \n",
    "                       'what_objects': what_objects,\n",
    "                      'locations': self.get_random_locations(num_objects_to_place)})\n",
    "        \n",
    "        if REMOVE_CLUTTER:\n",
    "            self.remove_clutter()\n",
    "            \n",
    "    def remove_clutter(self):\n",
    "        \"\"\"\n",
    "        This function removes vectors with too many objects and too much object occlusion\n",
    "        \"\"\"\n",
    "        \n",
    "        removed_vectors = 0\n",
    "        for index, vector in enumerate(self.augment_vector):\n",
    "            vector_area = 0\n",
    "            for i in range(vector['num_objects_to_place']):\n",
    "                vector_area += self.objects[vector['what_objects'][i]]['obj_area']\n",
    "            dist_btw_locations = cdist(vector['locations'], vector['locations'])\n",
    "            np.fill_diagonal(dist_btw_locations, np.inf)\n",
    "            if (vector_area > self.image_dimension[0] * self.image_dimension[1] * self.max_occupied_area or\n",
    "                        np.any(dist_btw_locations<self.min_dist_btw_locations)):\n",
    "                del self.augment_vector[index]\n",
    "                removed_vectors += 1\n",
    "            \n",
    "        if self.regenerate_augment_vector_count < self.generation_reattempts and removed_vectors is not 0:\n",
    "            self.create_augment_vector(NUM_OF_IMAGES= removed_vectors, CLEAR_AUGMENT_VECTOR=False)\n",
    "            self.regenerate_augment_vector_count += 1\n",
    "    \n",
    "    def get_random_locations(self, num_objects_to_place):\n",
    "        \n",
    "        \"\"\"\n",
    "        Generate a list of random (x,y) points..\n",
    "        \"\"\"\n",
    "        location = [[random.randrange(0, 440, 120), random.randrange(0, 600, 120)]\n",
    "               for _ in range(num_objects_to_place)]\n",
    "        \n",
    "        return np.array(location)\n",
    "    \n",
    "    def plot_img_and_label(self, image, label, img_num, obj_det_label=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        Visualize the augmented image, it's corresponding semantic segmentation \n",
    "        label and object detection label.\n",
    "        \n",
    "        preview_data: can be used to preview data within the notebook...\n",
    "        save_data_preview: can be used to save the plots...\n",
    "        \"\"\"\n",
    "        if self.preview_data or self.save_data_preview:\n",
    "            label = label.copy()\n",
    "            if obj_det_label is not None:\n",
    "                for l in obj_det_label:\n",
    "                    for i in range(l[1], l[3]+1):\n",
    "                        if i < self.image_dimension[0]:\n",
    "                            label[i, l[2]:l[2]+3] = len(label_def) + 1\n",
    "                            label[i, l[4]-3:l[4]] = len(label_def) + 1\n",
    "\n",
    "                    for i in range(l[2], l[4]+1):\n",
    "                        if i < self.image_dimension[1]:\n",
    "                            label[l[1]:l[1]+3, i] = len(label_def) + 1\n",
    "                            label[l[3]-3:l[3], i] = len(label_def) + 1\n",
    "\n",
    "            figure = plt.figure()\n",
    "            figure.set_figheight(15)\n",
    "            figure.set_figwidth(15)\n",
    "            figure.add_subplot(1, 2, 1)\n",
    "            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            figure.add_subplot(1, 2, 2)\n",
    "            plt.imshow(label)\n",
    "            if self.save_data_preview:\n",
    "                plt.savefig('./data_augmentation_results/image_and_gt/'+str(img_num)+'.png')\n",
    "                result = cv2.imread('./data_augmentation_results/image_and_gt/'+str(img_num)+'.png', 1)\n",
    "                result = result[320:750,50:1030,:]\n",
    "                cv2.imwrite('./data_augmentation_results/image_and_gt/'+str(img_num)+'.png', result)\n",
    "            plt.show() if self.preview_data else plt.close(figure)\n",
    "        \n",
    "    def find_obj_loc_and_vals(self, image, label, label_value, obj_name):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function returns a dictionary which links:\n",
    "            1. 'obj_loc' to (x,y) locations of the object obtained using \n",
    "                the label definition...\n",
    "            2. 'obj_vals' to the intensity values of the object in the \n",
    "                corresponding 'obj_loc'...\n",
    "            3. 'label_vals' to an array whose all elements is the value of\n",
    "                the object label...\n",
    "            4. 'obj_name' to the name of the object..\n",
    "            5. 'rect_points' to the coordinates of the points to obtain bounding rectangle.\n",
    "            6. 'obj_area' to the area occupied by the object in pixel space.\n",
    "        \n",
    "        \"\"\"\n",
    "        obj_loc = np.argwhere(label==label_value)\n",
    "        obj_vals = [image[tuple(loc)] for loc in obj_loc]\n",
    "        obj_vals = np.array(obj_vals)\n",
    "        label_vals = np.ones(len(obj_loc)) * label_value\n",
    "        rect_points = [min(obj_loc[:,0]), min(obj_loc[:,1]), max(obj_loc[:,0]), max(obj_loc[:,1])]\n",
    "        obj_area = (rect_points[2] - rect_points[0]) * (rect_points[3] - rect_points[1])\n",
    "        \n",
    "        return {'obj_loc': obj_loc, 'obj_vals': obj_vals, 'label_vals': label_vals, \n",
    "                'obj_name': obj_name, 'rect_points': rect_points, 'obj_area': obj_area}\n",
    "    \n",
    "    def get_different_scales(self, image, image_label, label_value, obj_name, obj_num):\n",
    "        \n",
    "        \"\"\"\n",
    "        This functions creates different scales of the object based on the\n",
    "        number of scales parameter and removes objects which are too small..\n",
    "        \"\"\"\n",
    "        \n",
    "        if type(self.num_of_scales) is np.ndarray:\n",
    "            num_scales = self.num_of_scales[obj_num]\n",
    "            scale_difference = 1.2/self.num_of_scales[obj_num]\n",
    "        else:\n",
    "            num_scales = self.num_of_scales\n",
    "            scale_difference = 1.2/self.num_of_scales\n",
    "        scales = [i * scale_difference for i in range(1, num_scales+1)]\n",
    "            \n",
    "        scaled_objects = list()\n",
    "\n",
    "        for i in range(0, num_scales):\n",
    "            scaled_objects.append(self.find_obj_loc_and_vals(\n",
    "                    cv2.resize(image, (0,0), fx=scales[i], fy=scales[i]), \n",
    "                    cv2.resize(image_label, (0,0), fx=scales[i], fy=scales[i]), \n",
    "                    label_value, obj_name))\n",
    "        \n",
    "        image_area = self.image_dimension[0] * self.image_dimension[1]\n",
    "        for index, obj in enumerate(scaled_objects):\n",
    "            if not (self.min_obj_area_percent/100 * image_area < obj['obj_area'] < \n",
    "                self.max_obj_area_percent/100 * image_area):\n",
    "                del scaled_objects[index]\n",
    "                self.num_objects -= 1\n",
    "\n",
    "        return scaled_objects\n",
    "    \n",
    "    def get_synthetic_objects_list(self, object_paths):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function reads all the images and its coresponding labels...\n",
    "        Creates a dictionary which maps the object name to the list of objects and labels...\n",
    "        \"\"\"\n",
    "        objects = list()\n",
    "        obj_num = -1\n",
    "        for key in tqdm.tqdm(self.label_def, desc= 'Loading images and gts class by class'):\n",
    "            if key is not 'background':\n",
    "                data_list = object_paths[key]\n",
    "                for data in data_list:\n",
    "                    obj_num += 1\n",
    "                    img = cv2.imread(data[0])\n",
    "                    label = cv2.imread(data[1], 0)\n",
    "                    objects += self.get_different_scales(img, label, label_def[key], key, obj_num)\n",
    "                    \n",
    "        return objects\n",
    "    \n",
    "    def get_augmented_image(self, original_image, original_label, obj_vals, location):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function gets the image and label which needs to be augmented, the object details\n",
    "        and the random location in which the object needs to be placed as arguments..\n",
    "        \n",
    "        The existing object location is shifted based on the location argument and the\n",
    "        intensity values of the object are now placed in the shifted location...\n",
    "        \n",
    "        The resultant augmented image and label is returned...\n",
    "        \"\"\"\n",
    "        augmented_image = original_image.copy()\n",
    "        augmented_label = original_label.copy()\n",
    "        obj_vals_to_augment = copy.deepcopy(obj_vals)\n",
    "        \n",
    "        row_shift = min(obj_vals_to_augment['obj_loc'][:,0]) - location[0]\n",
    "        col_shift = min(obj_vals_to_augment['obj_loc'][:,1]) - location[1]\n",
    "        obj_vals_to_augment['obj_loc'][:,0] -= row_shift\n",
    "        obj_vals_to_augment['obj_loc'][:,1] -= col_shift\n",
    "\n",
    "        for index,loc in enumerate(obj_vals_to_augment['obj_loc']):\n",
    "            if 0 < loc[0] < self.image_dimension[0] and 0 < loc[1] < self.image_dimension[1]:\n",
    "                augmented_image[tuple(loc)] = obj_vals_to_augment['obj_vals'][index]\n",
    "                augmented_label[tuple(loc)] = obj_vals_to_augment['label_vals'][index]\n",
    "\n",
    "        if self.get_obj_det_label:\n",
    "            rect_points = [r - s for r, s in zip(obj_vals_to_augment['rect_points'], \n",
    "                                                 [row_shift, col_shift, row_shift, col_shift])]\n",
    "            \n",
    "            obj_det_label = [obj_vals_to_augment['obj_name']] + rect_points\n",
    "            return augmented_image, augmented_label, obj_det_label\n",
    "\n",
    "        return augmented_image, augmented_label\n",
    "    \n",
    "    def perform_augmentation(self, PREVIEW_DATA=False, SAVE_DATA_PREVIEW=False, \n",
    "                             GET_OBJ_DET_LABEL=True, IMG_SAVE_PATH='./data_augmentation_results/image/',\n",
    "                            LABEL_SAVE_PATH='./data_augmentation_results/ground_truth/',\n",
    "                            OBJ_DET_LABEL_SAVE_PATH='./data_augmentation_results/obj_det/',\n",
    "                            START_INDEX_OF_NAME= 0):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function goes through the augment vector and performs augmentation \n",
    "        for each augment vector.. The result is saved along with semantic segmentation\n",
    "        labels and object detection labels (if get_obj_det_label is true)...\n",
    "        \n",
    "        In each augment vector, objects in 'what_objects' is taken and pasted on top\n",
    "        of the 'background_image' in the augment vector... \n",
    "        \n",
    "        The augmented image and label are then saved. Object detection labels are saved\n",
    "        in a csv (one for every augment vector) if get_obj_det_label is true...\n",
    "        \"\"\"\n",
    "        \n",
    "        self.preview_data = PREVIEW_DATA\n",
    "        self.save_data_preview = SAVE_DATA_PREVIEW\n",
    "        self.get_obj_det_label = GET_OBJ_DET_LABEL\n",
    "        \n",
    "        obj_det_label = list()\n",
    "        background_label = np.ones(tuple(self.image_dimension)) * self.label_def['background']\n",
    "        for index, vector in enumerate(tqdm.tqdm(self.augment_vector, desc= 'Generating synthetic images')):\n",
    "            augmented_image, augmented_label = vector['background_image'], background_label.copy()\n",
    "            obj_det_label.clear()\n",
    "            for i in range(vector['num_objects_to_place']):\n",
    "\n",
    "                if self.get_obj_det_label:\n",
    "                    augmented_image, augmented_label, rect_label = self.get_augmented_image(augmented_image, \n",
    "                                                        augmented_label, \n",
    "                                                           self.objects[vector['what_objects'][i]], \n",
    "                                                               vector['locations'][i])\n",
    "                    obj_det_label.append(rect_label)\n",
    "                else:\n",
    "                    augmented_image, augmented_label = self.get_augmented_image(augmented_image, \n",
    "                                                        augmented_label, \n",
    "                                                           self.objects[vector['what_objects'][i]], \n",
    "                                                               vector['locations'][i])\n",
    "\n",
    "            if self.get_obj_det_label:\n",
    "                self.plot_img_and_label(augmented_image, augmented_label, \n",
    "                                        index+START_INDEX_OF_NAME, obj_det_label)\n",
    "                cv2.imwrite(IMG_SAVE_PATH+str(index+START_INDEX_OF_NAME)+'.jpg', augmented_image)\n",
    "                cv2.imwrite(LABEL_SAVE_PATH+str(index+START_INDEX_OF_NAME)+'.png', augmented_label)\n",
    "                with open(OBJ_DET_LABEL_SAVE_PATH+str(index+START_INDEX_OF_NAME)+'.csv','w') as f:\n",
    "                    wr = csv.writer(f,delimiter=',')\n",
    "                    [wr.writerow(l) for l in obj_det_label]\n",
    "\n",
    "            else:\n",
    "                plot_img_and_label(augmented_image, augmented_label, \n",
    "                                   index+START_INDEX_OF_NAME)\n",
    "                cv2.imwrite(IMG_SAVE_PATH+str(index+START_INDEX_OF_NAME)+'.jpg', augmented_image)\n",
    "                cv2.imwrite(LABEL_SAVE_PATH+str(index+START_INDEX_OF_NAME)+'.png', augmented_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and gts class by class: 100%|██████████| 19/19 [00:36<00:00,  1.94s/it]\n"
     ]
    }
   ],
   "source": [
    "label_def = {'f20_20_B': 1, 's40_40_B': 2, 'f20_20_G': 3, 's40_40_G': 4,  'm20_100': 5, \n",
    "             'm20': 6, 'm30': 7, 'r20': 8, 'bearing_box_ax01': 9, 'bearing': 10, 'axis': 11, \n",
    "             'distance_tube': 12, 'motor': 13, 'container_box_blue': 14, 'container_box_red': 15, \n",
    "             'bearing_box_ax16': 16, 'em_01': 17, 'em_02': 18, 'background': 19}\n",
    "augmenter = DataAugmentation(label_def, NUM_OF_SCALES= 'RANDOMIZE',\n",
    "                            IMAGE_PATH='./objects/dataset_split/training/image/',\n",
    "                            LABEL_PATH='./objects/dataset_split/training/label/',\n",
    "                            BACKGROUNDS_PATH='./backgrounds/training/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating synthetic images: 100%|██████████| 7104/7104 [1:06:32<00:00,  1.78it/s]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "augmenter.create_augment_vector(NUM_OF_IMAGES= 7104, MAX_OBJECTS_PER_IMAGE= 25)\n",
    "augmenter.perform_augmentation(SAVE_DATA_PREVIEW= True, PREVIEW_DATA= False,\n",
    "                              IMG_SAVE_PATH='./objects/augmented/training/image/',\n",
    "                              LABEL_SAVE_PATH='./objects/augmented/training/label/',\n",
    "                              START_INDEX_OF_NAME=0)\n",
    "time_taken = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken to generate synthetic images is 3996.4729475975037 seconds\n"
     ]
    }
   ],
   "source": [
    "print ('Total time taken to generate synthetic images is {} seconds'.format(time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and gts class by class: 100%|██████████| 19/19 [00:05<00:00,  3.26it/s]\n"
     ]
    }
   ],
   "source": [
    "augmenter = DataAugmentation(label_def, NUM_OF_SCALES= 'RANDOMIZE',\n",
    "                            IMAGE_PATH='./objects/dataset_split/validation/image/',\n",
    "                            LABEL_PATH='./objects/dataset_split/validation/label/',\n",
    "                            BACKGROUNDS_PATH='./backgrounds/validation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating synthetic images: 100%|██████████| 870/870 [07:44<00:00,  1.87it/s]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "augmenter.create_augment_vector(NUM_OF_IMAGES= 870, MAX_OBJECTS_PER_IMAGE= 25)\n",
    "augmenter.perform_augmentation(SAVE_DATA_PREVIEW= True, PREVIEW_DATA= False,\n",
    "                              IMG_SAVE_PATH='./objects/augmented/validation/image/',\n",
    "                              LABEL_SAVE_PATH='./objects/augmented/validation/label/',\n",
    "                              START_INDEX_OF_NAME=0)\n",
    "time_taken = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken to generate synthetic images is 464.63704228401184 seconds\n"
     ]
    }
   ],
   "source": [
    "print ('Total time taken to generate synthetic images is {} seconds'.format(time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and gts class by class: 100%|██████████| 19/19 [00:06<00:00,  3.07it/s]\n"
     ]
    }
   ],
   "source": [
    "augmenter = DataAugmentation(label_def, NUM_OF_SCALES= 'RANDOMIZE',\n",
    "                            IMAGE_PATH='./objects/dataset_split/test/image/',\n",
    "                            LABEL_PATH='./objects/dataset_split/test/label/',\n",
    "                            BACKGROUNDS_PATH='./backgrounds/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating synthetic images: 100%|██████████| 870/870 [07:49<00:00,  1.85it/s]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "augmenter.create_augment_vector(NUM_OF_IMAGES= 870, MAX_OBJECTS_PER_IMAGE= 25)\n",
    "augmenter.perform_augmentation(SAVE_DATA_PREVIEW= True, PREVIEW_DATA= False,\n",
    "                              IMG_SAVE_PATH='./objects/augmented/test/image/',\n",
    "                              LABEL_SAVE_PATH='./objects/augmented/test/label/',\n",
    "                              START_INDEX_OF_NAME=0)\n",
    "time_taken = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken to generate synthetic images is 469.7502284049988 seconds\n"
     ]
    }
   ],
   "source": [
    "print ('Total time taken to generate synthetic images is {} seconds'.format(time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "5. Fix overlapping obj detection labels..\n",
    "6. When large object leaves pixel space, object detection label is too large.. see ./problem_6.png...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "PATH = './backgrounds/'\n",
    "files = os.listdir(PATH)\n",
    "for index, file in enumerate(files):\n",
    "    if index+1<=9:\n",
    "        os.rename(PATH+file, PATH+'background_000'+str(index+1)+'.'+file.split('.')[-1])\n",
    "    elif index+1<=99:\n",
    "        os.rename(PATH+file, PATH+'background_00'+str(index+1)+'.'+file.split('.')[-1])\n",
    "    else:\n",
    "        os.rename(PATH+file, PATH+'background_0'+str(index+1)+'.'+file.split('.')[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
