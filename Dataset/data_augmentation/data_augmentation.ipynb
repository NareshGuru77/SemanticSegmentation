{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "import warnings\n",
    "np.seterr(all='raise')\n",
    "warnings.filterwarnings('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAugmentation():\n",
    "    \n",
    "    def __init__(self, label_def, IMAGE_DIMENSION= [480, 640], NUM_OF_SCALES= 2, \n",
    "                   IMAGE_PATH= './objects/image', LABEL_PATH= './objects/label', IMG_TYPE= '.jpg',\n",
    "                    MIN_OBJ_AREA_PERCENT= 0.3, MAX_OBJ_AREA_PERCENT= 70):\n",
    "\n",
    "        self.label_def = label_def\n",
    "        self.image_dimension = IMAGE_DIMENSION\n",
    "        self.image_path = IMAGE_PATH\n",
    "        self.label_path = LABEL_PATH\n",
    "        self.img_type = IMG_TYPE\n",
    "        self.min_obj_area_percent = MIN_OBJ_AREA_PERCENT\n",
    "        self.max_obj_area_percent = MAX_OBJ_AREA_PERCENT\n",
    "        self.regenerate_augment_vector_count = 0\n",
    "        \n",
    "        files_count, object_paths = self.fetch_image_gt_paths()\n",
    "        \n",
    "        if NUM_OF_SCALES is 'RANDOMIZE':\n",
    "            self.num_of_scales = np.random.randint(1, 5, size= files_count)\n",
    "            self.num_objects = np.sum(self.num_of_scales)\n",
    "        else:\n",
    "            self.num_of_scales = NUM_OF_SCALES\n",
    "            self.num_objects = self.num_of_scales * files_count\n",
    "            \n",
    "        self.background_images = self.get_background_images()\n",
    "        self.objects = self.get_synthetic_objects_list(object_paths)\n",
    "        self.augment_vector = list()\n",
    "    \n",
    "    def fetch_image_gt_paths(self):\n",
    "        \"\"\"\n",
    "        This function counts the number of annotated images and\n",
    "        fetches the path of the images and corresponding labels..\n",
    "        \n",
    "        Returns the number of annotated images and a dictionary mapping\n",
    "        the object name to the corresponding image and label paths...\n",
    "        \"\"\"\n",
    "        object_paths = dict()\n",
    "        files_count = 0\n",
    "        for obj_dir in os.listdir(self.label_path):\n",
    "            obj_files = list()\n",
    "            for files in sorted(os.listdir(os.path.join(self.label_path, obj_dir))):\n",
    "                files_count += 1\n",
    "                obj_files.append([os.path.join(self.image_path, obj_dir, files.split('.')[0]+self.img_type), \n",
    "                         os.path.join(self.label_path, obj_dir, files)])\n",
    "            object_paths[obj_dir] = obj_files.copy()\n",
    "            \n",
    "        return files_count, object_paths\n",
    "    \n",
    "    def get_background_images(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function reads the background images and creates a list...\n",
    "        \"\"\"\n",
    "\n",
    "        background_files = os.listdir('./backgrounds')\n",
    "        background_files = [os.path.join('./backgrounds', file) for file in background_files]\n",
    "        background_images = list()\n",
    "        for file in background_files:\n",
    "            background_images.append(cv2.imread(file))\n",
    "            \n",
    "        return background_images\n",
    "    \n",
    "    def create_augment_vector(self, augment_vector_length= None, remove_clutter= True,\n",
    "                             NUM_OF_IMAGES= 50, MAX_OBJECTS_PER_IMAGE= 6, GENERATION_REATTEMPTS= 50):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function creates a randomized augment vector, based on \n",
    "        which the images are augmented..\n",
    "        \n",
    "        # parameters which are randomized:\n",
    "            1. 'background_image': selects a random background image.\n",
    "                    It is also ensured that all backgrounds are selected once\n",
    "                    before randomizing again.\n",
    "                    \n",
    "            2. 'num_objects_to_place': number of objects to be placed in\n",
    "                    the image.\n",
    "            \n",
    "            3. 'what_objects': a list of random indices are created. Objects in\n",
    "                    the corresponding indices will be chosen for augmentation.\n",
    "                    \n",
    "            4. 'locations': randomized (x,y) in the pixel space for each object..\n",
    "        \"\"\"\n",
    "        \n",
    "        self.generation_reattempts = GENERATION_REATTEMPTS\n",
    "        num_of_images = NUM_OF_IMAGES if augment_vector_length is None else augment_vector_length\n",
    "        objects_index = np.arange(0, self.num_objects)\n",
    "\n",
    "        for i in range(num_of_images):\n",
    "            num_objects_to_place = np.random.randint(1, high= MAX_OBJECTS_PER_IMAGE)\n",
    "            what_objects = [objects_index[i] for i in range(num_objects_to_place)]\n",
    "    \n",
    "            if i % len(self.background_images) == 0:\n",
    "                np.random.shuffle(self.background_images)\n",
    "        \n",
    "            #if i % num_objects == 0:\n",
    "            np.random.shuffle(objects_index)\n",
    "        \n",
    "            self.augment_vector.append({'background_image': self.background_images[\n",
    "                                                            i % len(self.background_images)], \n",
    "                       'num_objects_to_place': num_objects_to_place, \n",
    "                       'what_objects': what_objects,\n",
    "                      'locations': self.get_random_locations(num_objects_to_place)})\n",
    "        \n",
    "        if remove_clutter:\n",
    "            self.remove_clutter()\n",
    "            \n",
    "    def remove_clutter(self):\n",
    "        \n",
    "        removed_vectors = 0\n",
    "        for index, vector in enumerate(self.augment_vector):\n",
    "            vector_area = 0\n",
    "            for i in range(vector['num_objects_to_place']):\n",
    "                vector_area += self.objects[vector['what_objects'][i]]['obj_area']\n",
    "            if vector_area > self.image_dimension[0] * self.image_dimension[1] * 0.8:\n",
    "                del self.augment_vector[index]\n",
    "                removed_vectors += 1\n",
    "            \n",
    "        if self.regenerate_augment_vector_count < self.generation_reattempts and removed_vectors is not 0:\n",
    "            self.create_augment_vector(augment_vector_length= removed_vectors)\n",
    "            self.regenerate_augment_vector_count += 1\n",
    "    \n",
    "    def get_random_locations(self, num_objects_to_place):\n",
    "        \n",
    "        \"\"\"\n",
    "        Generate a list of random (x,y) points..\n",
    "        \"\"\"\n",
    "        location = [[random.randrange(0, 440, 120), random.randrange(0, 600, 120)]\n",
    "               for _ in range(num_objects_to_place)]\n",
    "        \n",
    "        return np.array(location)\n",
    "    \n",
    "    def plot_img_and_label(self, image, label, img_num, obj_det_label= None):\n",
    "        \n",
    "        \"\"\"\n",
    "        Visualize the augmented image, it's corresponding semantic segmentation \n",
    "        label and object detection label.\n",
    "        \n",
    "        preview_data: can be used to preview data within the notebook...\n",
    "        save_data_preview: can be used to save the plots...\n",
    "        \"\"\"\n",
    "        if self.preview_data or self.save_data_preview:\n",
    "            label = label.copy()\n",
    "            if obj_det_label is not None:\n",
    "                for l in obj_det_label:\n",
    "                    for i in range(l[1], l[3]+1):\n",
    "                        if i < self.image_dimension[0]:\n",
    "                            label[i, l[2]:l[2]+3] = len(label_def) + 1\n",
    "                            label[i, l[4]-3:l[4]] = len(label_def) + 1\n",
    "\n",
    "                    for i in range(l[2], l[4]+1):\n",
    "                        if i < self.image_dimension[1]:\n",
    "                            label[l[1]:l[1]+3, i] = len(label_def) + 1\n",
    "                            label[l[3]-3:l[3], i] = len(label_def) + 1\n",
    "\n",
    "            figure = plt.figure()\n",
    "            figure.set_figheight(15)\n",
    "            figure.set_figwidth(15)\n",
    "            figure.add_subplot(1, 2, 1)\n",
    "            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            figure.add_subplot(1, 2, 2)\n",
    "            plt.imshow(label)\n",
    "            if self.save_data_preview:\n",
    "                plt.savefig('./data_augmentation_results/image_and_gt/'+str(img_num)+'.png')\n",
    "                result = cv2.imread('./data_augmentation_results/image_and_gt/'+str(img_num)+'.png', 1)\n",
    "                result = result[320:750,50:1030,:]\n",
    "                cv2.imwrite('./data_augmentation_results/image_and_gt/'+str(img_num)+'.png', result)\n",
    "            plt.show() if self.preview_data else plt.close(figure)\n",
    "        \n",
    "    def find_obj_loc_and_vals(self, image, label, label_value, obj_name):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function returns a dictionary which links:\n",
    "            1. 'obj_loc' to (x,y) locations of the object obtained using \n",
    "                the label definition...\n",
    "            2. 'obj_vals' to the intensity values of the object in the \n",
    "                corresponding 'obj_loc'...\n",
    "            3. 'label_vals' to an array whose all elements is the value of\n",
    "                the object label...\n",
    "            4. 'obj_name' to the name of the object..\n",
    "        \n",
    "        \"\"\"\n",
    "        obj_loc = np.argwhere(label==label_value)\n",
    "        obj_vals = [image[tuple(loc)] for loc in obj_loc]\n",
    "        obj_vals = np.array(obj_vals)\n",
    "        label_vals = np.ones(len(obj_loc)) * label_value\n",
    "        rect_points = [min(obj_loc[:,0]), min(obj_loc[:,1]), max(obj_loc[:,0]), max(obj_loc[:,1])]\n",
    "        obj_area = (rect_points[2] - rect_points[0]) * (rect_points[3] - rect_points[1])\n",
    "        \n",
    "        return {'obj_loc': obj_loc, 'obj_vals': obj_vals, 'label_vals': label_vals, \n",
    "                'obj_name': obj_name, 'rect_points': rect_points, 'obj_area': obj_area}\n",
    "    \n",
    "    def get_different_scales(self, image, image_label, label_value, obj_name, obj_num):\n",
    "        \n",
    "        \"\"\"\n",
    "        This functions creates different scales of the object based on the\n",
    "        number of scales parameter...\n",
    "        \"\"\"\n",
    "        \n",
    "        if type(self.num_of_scales) is np.ndarray:\n",
    "            num_scales = self.num_of_scales[obj_num]\n",
    "            scale_difference = 1/self.num_of_scales[obj_num]\n",
    "        else:\n",
    "            num_scales = self.num_of_scales\n",
    "            scale_difference = 1/self.num_of_scales\n",
    "        scales = [i * scale_difference for i in range(1, num_scales+1)]\n",
    "            \n",
    "        scaled_objects = list()\n",
    "\n",
    "        for i in range(0, num_scales):\n",
    "            scaled_objects.append(self.find_obj_loc_and_vals(\n",
    "                    cv2.resize(image, (0,0), fx=scales[i], fy=scales[i]), \n",
    "                    cv2.resize(image_label, (0,0), fx=scales[i], fy=scales[i]), \n",
    "                    label_value, obj_name))\n",
    "        \n",
    "        image_area = self.image_dimension[0] * self.image_dimension[1]\n",
    "        remove_objects = list()\n",
    "        for obj in scaled_objects:\n",
    "            if not (self.min_obj_area_percent/100 * image_area < obj['obj_area'] < \n",
    "                self.max_obj_area_percent/100 * image_area):\n",
    "                remove_objects.append(obj)\n",
    "                \n",
    "        for obj in remove_objects:\n",
    "            scaled_objects.remove(obj)\n",
    "            self.num_objects -= 1\n",
    "\n",
    "        return scaled_objects\n",
    "    \n",
    "    def get_synthetic_objects_list(self, object_paths):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function reads all the images and its coresponding labels...\n",
    "        Creates a dictionary which maps the object name to the list of objects and labels...\n",
    "        \"\"\"\n",
    "        objects = list()\n",
    "        obj_num = -1\n",
    "        for key in tqdm.tqdm(self.label_def, desc= 'Loading images and gts class by class'):\n",
    "            if key is not 'background':\n",
    "                data_list = object_paths[key]\n",
    "                for data in data_list:\n",
    "                    obj_num += 1\n",
    "                    img = cv2.imread(data[0])\n",
    "                    label = cv2.imread(data[1], 0)\n",
    "                    objects += self.get_different_scales(img, label, label_def[key], key, obj_num)\n",
    "                    \n",
    "        return objects\n",
    "    \n",
    "    def get_augmented_image(self, original_image, original_label, obj_vals, location):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function gets the image and label which needs to be augmented, the object details\n",
    "        and the random location in which the object needs to be placed as arguments..\n",
    "        \n",
    "        The existing object location is shifted based on the location argument and the\n",
    "        intensity values of the object are now placed in the shifted location...\n",
    "        \n",
    "        The resultant augmented image and label is returned...\n",
    "        \"\"\"\n",
    "        augmented_image = original_image.copy()\n",
    "        augmented_label = original_label.copy()\n",
    "        obj_vals_to_augment = copy.deepcopy(obj_vals)\n",
    "        \n",
    "        row_shift = min(obj_vals_to_augment['obj_loc'][:,0]) - location[0]\n",
    "        col_shift = min(obj_vals_to_augment['obj_loc'][:,1]) - location[1]\n",
    "        obj_vals_to_augment['obj_loc'][:,0] -= row_shift\n",
    "        obj_vals_to_augment['obj_loc'][:,1] -= col_shift\n",
    "\n",
    "        for index,loc in enumerate(obj_vals_to_augment['obj_loc']):\n",
    "            if 0 < loc[0] < self.image_dimension[0] and 0 < loc[1] < self.image_dimension[1]:\n",
    "                augmented_image[tuple(loc)] = obj_vals_to_augment['obj_vals'][index]\n",
    "                augmented_label[tuple(loc)] = obj_vals_to_augment['label_vals'][index]\n",
    "\n",
    "        if self.get_obj_det_label:\n",
    "            rect_points = [r - s for r, s in zip(obj_vals_to_augment['rect_points'], \n",
    "                                                 [row_shift, col_shift, row_shift, col_shift])]\n",
    "            \n",
    "            obj_det_label = [obj_vals_to_augment['obj_name']] + rect_points\n",
    "            return augmented_image, augmented_label, obj_det_label\n",
    "\n",
    "        return augmented_image, augmented_label\n",
    "    \n",
    "    def perform_augmentation(self, preview_data= False, save_data_preview= False, get_obj_det_label= True):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function goes through the augment vector and performs augmentation \n",
    "        for each augment vector.. The result is saved along with semantic segmentation\n",
    "        labels and object detection labels (if get_obj_det_label is true)...\n",
    "        \n",
    "        In each augment vector, objects in 'what_objects' is taken and pasted on top\n",
    "        of the 'background_image' in the augment vector... \n",
    "        \n",
    "        The augmented image and label are then saved. Object detection labels are saved\n",
    "        in a csv (one for every augment vector) if get_obj_det_label is true...\n",
    "        \"\"\"\n",
    "        \n",
    "        self.preview_data = preview_data\n",
    "        self.save_data_preview = save_data_preview\n",
    "        self.get_obj_det_label = get_obj_det_label\n",
    "        \n",
    "        obj_det_label = list()\n",
    "        background_label = np.ones(tuple(self.image_dimension)) * self.label_def['background']\n",
    "        for index, vector in enumerate(tqdm.tqdm(self.augment_vector, desc= 'Generating synthetic images')):\n",
    "            augmented_image, augmented_label = vector['background_image'], background_label.copy()\n",
    "            obj_det_label.clear()\n",
    "            for i in range(vector['num_objects_to_place']):\n",
    "\n",
    "                if self.get_obj_det_label:\n",
    "                    augmented_image, augmented_label, rect_label = self.get_augmented_image(augmented_image, \n",
    "                                                        augmented_label, \n",
    "                                                           self.objects[vector['what_objects'][i]], \n",
    "                                                               vector['locations'][i])\n",
    "                    obj_det_label.append(rect_label)\n",
    "                else:\n",
    "                    augmented_image, augmented_label = self.get_augmented_image(augmented_image, \n",
    "                                                        augmented_label, \n",
    "                                                           self.objects[vector['what_objects'][i]], \n",
    "                                                               vector['locations'][i])\n",
    "\n",
    "            if self.get_obj_det_label:\n",
    "                self.plot_img_and_label(augmented_image, augmented_label, index, obj_det_label)\n",
    "                cv2.imwrite('./data_augmentation_results/image/'+str(index)+'.png', augmented_image)\n",
    "                cv2.imwrite('./data_augmentation_results/ground_truth/'+str(index)+'.png', augmented_label)\n",
    "                with open('./data_augmentation_results/obj_det/'+str(index)+'.csv','w') as f:\n",
    "                    wr = csv.writer(f,delimiter=',')\n",
    "                    [wr.writerow(l) for l in obj_det_label]\n",
    "\n",
    "            else:\n",
    "                plot_img_and_label(augmented_image, augmented_label, index)\n",
    "                cv2.imwrite('./data_augmentation_results/image/'+str(index)+'.png', augmented_image)\n",
    "                cv2.imwrite('./data_augmentation_results/ground_truth/'+str(index)+'.png', augmented_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images and gts class by class: 100%|██████████| 19/19 [00:47<00:00,  2.51s/it]\n"
     ]
    }
   ],
   "source": [
    "label_def = {'f20_20_B': 1, 's40_40_B': 2, 'f20_20_G': 3, 's40_40_G': 4,  'm20_100': 5, \n",
    "             'm20': 6, 'm30': 7, 'r20': 8, 'bearing_box_ax01': 9, 'bearing': 10, 'axis': 11, \n",
    "             'distance_tube': 12, 'motor': 13, 'container_box_blue': 14, 'container_box_red': 15, \n",
    "             'bearing_box_ax16': 16, 'em_01': 17, 'em_02': 18, 'background': 19}\n",
    "augmenter = DataAugmentation(label_def, NUM_OF_SCALES= 'RANDOMIZE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating synthetic images:   4%|▍         | 190/5000 [02:06<53:33,  1.50it/s]"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-470613cc93ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0maugmenter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_augment_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_OF_IMAGES\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_OBJECTS_PER_IMAGE\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maugmenter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform_augmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_data_preview\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreview_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-41d7cc5d04ab>\u001b[0m in \u001b[0;36mperform_augmentation\u001b[0;34m(self, preview_data, save_data_preview, get_obj_det_label)\u001b[0m\n\u001b[1;32m    308\u001b[0m                                                         \u001b[0maugmented_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                                                            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'what_objects'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                                                                vector['locations'][i])\n\u001b[0m\u001b[1;32m    311\u001b[0m                     \u001b[0mobj_det_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrect_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-41d7cc5d04ab>\u001b[0m in \u001b[0;36mget_augmented_image\u001b[0;34m(self, original_image, original_label, obj_vals, location)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mresultant\u001b[0m \u001b[0maugmented\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \"\"\"\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0maugmented_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0maugmented_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mobj_vals_to_augment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "augmenter.create_augment_vector(NUM_OF_IMAGES= 5000, MAX_OBJECTS_PER_IMAGE= 18)\n",
    "augmenter.perform_augmentation(save_data_preview= True, preview_data= False)\n",
    "time_taken = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken to generate synthetic images is 60.456636905670166 seconds\n"
     ]
    }
   ],
   "source": [
    "print ('Total time taken to generate synthetic images is {} seconds'.format(time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n4. Eliminate cluttered augment vectors..\\n5. Fix overlapping obj detection labels..\\n6. When large object leaves pixel space, object detection label is too large.. see ./problem_6.png...\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "4. Eliminate cluttered augment vectors..\n",
    "5. Fix overlapping obj detection labels..\n",
    "6. When large object leaves pixel space, object detection label is too large.. see ./problem_6.png...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "PATH = './backgrounds/'\n",
    "files = os.listdir(PATH)\n",
    "for index, file in enumerate(files):\n",
    "    if index+1<=9:\n",
    "        os.rename(PATH+file, PATH+'background_000'+str(index+1)+'.'+file.split('.')[-1])\n",
    "    elif index+1<=99:\n",
    "        os.rename(PATH+file, PATH+'background_00'+str(index+1)+'.'+file.split('.')[-1])\n",
    "    else:\n",
    "        os.rename(PATH+file, PATH+'background_0'+str(index+1)+'.'+file.split('.')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
