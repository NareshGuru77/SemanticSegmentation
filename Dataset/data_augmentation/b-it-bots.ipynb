{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "import time\n",
    "import tqdm\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import warnings\n",
    "np.seterr(all='raise')\n",
    "warnings.filterwarnings('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class B_it_bots_Segmentation_Dataset():\n",
    "    \n",
    "    def __init__(self, label_def, IMAGE_DIMENSION = [128, 128],\n",
    "                     IMAGE_PATH='./objects/image', \n",
    "                     LABEL_PATH='./objects/label', IMG_TYPE='.jpg',\n",
    "                    BACKGROUNDS_PATH ='./backgrounds/training/',\n",
    "                    NUMBER_OF_BACKGROUNDS=20, NUM_OF_SCALES=20,\n",
    "                    EXCLUDE_CLASSES=['motor', 'bearing_box_ax01', \n",
    "                                     'em_01', 'em_02', 'r20']):\n",
    "        \n",
    "        self.label_def = label_def\n",
    "        self.image_dimension = IMAGE_DIMENSION\n",
    "        self.image_path = IMAGE_PATH\n",
    "        self.label_path = LABEL_PATH\n",
    "        self.img_type = IMG_TYPE\n",
    "        self.num_of_scales = NUM_OF_SCALES\n",
    "        self.exclude_classes = EXCLUDE_CLASSES\n",
    "        \n",
    "        self.resize_images = lambda img_list: [cv2.resize(img, tuple(self.image_dimension))\n",
    "                                    for img in img_list]\n",
    "        \n",
    "        self.object_paths = self.fetch_image_gt_paths()\n",
    "        self.background_images = self.get_background_images(\n",
    "                                        BACKGROUNDS_PATH, NUMBER_OF_BACKGROUNDS)\n",
    "        self.objects_to_details = self.get_synthetic_objects_list()\n",
    "    \n",
    "    def fetch_image_gt_paths(self):\n",
    "        \n",
    "        object_paths = dict()\n",
    "        for clsses in os.listdir(self.label_path):\n",
    "            if not any(clsses == exclude\n",
    "                   for exclude in self.exclude_classes):\n",
    "                cls_path = os.path.join(self.label_path, clsses)\n",
    "                obj_files = list()\n",
    "                for files in sorted(os.listdir(cls_path)):\n",
    "                    obj_files.append([os.path.join(self.image_path, clsses, \n",
    "                            files.split('.')[0]+self.img_type), \n",
    "                             os.path.join(self.label_path, clsses, files)])\n",
    "                object_paths[clsses] = obj_files.copy()\n",
    "            \n",
    "        return object_paths\n",
    "    \n",
    "    \n",
    "    def get_background_images(self, backgrounds_path,\n",
    "                             number_of_backgrounds):\n",
    "        \n",
    "        np.random.seed(0)\n",
    "        background_files = os.listdir(backgrounds_path)\n",
    "        background_files = [os.path.join(backgrounds_path, file) \n",
    "                            for file in background_files]\n",
    "        np.random.shuffle(background_files)\n",
    "        background_files = background_files[0:number_of_backgrounds]\n",
    "        background_images = list()\n",
    "        for file in background_files:\n",
    "            background_images.append(cv2.imread(file))\n",
    "        \n",
    "        background_images = self.resize_images(background_images)\n",
    "        return background_images\n",
    "    \n",
    "    \n",
    "    def find_obj_loc_and_vals(self, image, label, label_value, obj_name):\n",
    "        \n",
    "        obj_loc = np.argwhere(label==label_value)\n",
    "        obj_vals = [image[tuple(loc)] for loc in obj_loc]\n",
    "        obj_vals = np.array(obj_vals)\n",
    "        label_vals = np.ones(len(obj_loc)) * label_value\n",
    "        rect_points = [min(obj_loc[:,0]), min(obj_loc[:,1]), max(obj_loc[:,0]), max(obj_loc[:,1])]\n",
    "        obj_area = (rect_points[2] - rect_points[0]) * (rect_points[3] - rect_points[1])\n",
    "        \n",
    "        return {'obj_loc': obj_loc, 'obj_vals': obj_vals, 'label_vals': label_vals, \n",
    "                'obj_name': obj_name, 'rect_points': rect_points, 'obj_area': obj_area}\n",
    "    \n",
    "    def get_different_scales(self, image, image_label, label_value, obj_name):\n",
    "        \n",
    "        scales = np.linspace(0.3, 1.2, num= self.num_of_scales*2)\n",
    "        np.random.shuffle(scales)\n",
    "        scales = scales[0: self.num_of_scales]\n",
    "            \n",
    "        scaled_objects = list()\n",
    "\n",
    "        for i in range(0, self.num_of_scales):\n",
    "            resized_img = cv2.resize(image, (0,0), fx=scales[i], fy=scales[i])\n",
    "            resized_label = cv2.resize(image_label, (0,0), fx=scales[i], fy=scales[i])\n",
    "            \n",
    "            if not np.any(resized_label==label_value):\n",
    "                resized_img, resized_label = image, image_label\n",
    "                \n",
    "            scaled_objects.append(self.find_obj_loc_and_vals(\n",
    "                    resized_img, resized_label, \n",
    "                    label_value, obj_name))\n",
    "\n",
    "        return scaled_objects\n",
    "    \n",
    "    def get_synthetic_objects_list(self):\n",
    "        \n",
    "        objects = list()\n",
    "        objects_to_details = dict()\n",
    "    \n",
    "        for key in self.object_paths.keys():\n",
    "            path_list = np.array(self.object_paths[key]).T\n",
    "            images_in_cls = [cv2.imread(path, 1) for path in path_list[0]]\n",
    "            labels_in_cls = [cv2.imread(path, 0) for path in path_list[1]]\n",
    "            images_in_cls = self.resize_images(images_in_cls)\n",
    "            labels_in_cls = self.resize_images(labels_in_cls)\n",
    "            for img, label in zip(images_in_cls, labels_in_cls):\n",
    "                objects += self.get_different_scales(\n",
    "                        img, label, label_def[key], key)\n",
    "            objects_to_details[key] = objects.copy()\n",
    "            objects.clear()\n",
    "\n",
    "        return objects_to_details\n",
    "    \n",
    "    def get_visual_image(self, label):\n",
    "        colormap = np.asarray([[128, 64, 128], [244, 35, 232], [70, 70, 70], \n",
    "                               [102, 102, 156], [190, 153, 153], [153, 153, 153], \n",
    "                               [250, 170, 30], [220, 220, 0], [107, 142, 35], \n",
    "                               [152, 251, 152], [70, 130, 180], [220, 20, 60], \n",
    "                               [255, 0, 0], [0, 0, 142], [0, 0, 70], \n",
    "                                [0, 60, 100], [0, 80, 100],[0, 0, 230],\n",
    "                                  [119, 11, 32], [0, 0, 0]])\n",
    "        \n",
    "        return colormap[np.array(label, dtype=np.uint8)]\n",
    "        \n",
    "            \n",
    "    def perform_augmentation(self, SAVE_DIR='./b_it/',\n",
    "                            NUM_OF_IMAGES=20, _IMAGE_FORMAT='%04d', \n",
    "                            _VISUAL_FORMAT='%04d', _RAW_FORMAT='%04d'):\n",
    "        \n",
    "        background_label = np.ones(tuple(self.image_dimension)) * self.label_def['background']\n",
    "        \n",
    "        for key in self.object_paths.keys():\n",
    "            clss_objects = self.objects_to_details[key]\n",
    "            for img_number in range(NUM_OF_IMAGES):\n",
    "                augmented_image = self.background_images[img_number].copy()\n",
    "                augmented_label = background_label.copy()\n",
    "                obj_details = copy.deepcopy(clss_objects[img_number])\n",
    "                location_offsets = [0.25* dim for dim in self.image_dimension]\n",
    "                location = [random.randrange(0, self.image_dimension[0] - location_offsets[0], \n",
    "                                             location_offsets[0]), \n",
    "                            random.randrange(0, self.image_dimension[1] - location_offsets[1],\n",
    "                                             location_offsets[1])]\n",
    "\n",
    "                row_shift = min(obj_details['obj_loc'][:,0]) - location[0]\n",
    "                col_shift = min(obj_details['obj_loc'][:,1]) - location[1]\n",
    "                obj_details['obj_loc'][:,0] -= row_shift\n",
    "                obj_details['obj_loc'][:,1] -= col_shift\n",
    "\n",
    "                for index,loc in enumerate(obj_details['obj_loc']):\n",
    "                    if 0 < loc[0] < self.image_dimension[0] and 0 < loc[1] < self.image_dimension[1]:\n",
    "                        augmented_image[tuple(loc)] = obj_details['obj_vals'][index]\n",
    "                        augmented_label[tuple(loc)] = obj_details['label_vals'][index]\n",
    "                \n",
    "                img_directory = os.path.join(SAVE_DIR, 'image', \n",
    "                                             obj_details['obj_name'])\n",
    "                if not os.path.isdir(img_directory): \n",
    "                    os.makedirs(img_directory)\n",
    "                raw_directory = os.path.join(SAVE_DIR, 'raw',\n",
    "                                            obj_details['obj_name'])\n",
    "                if not os.path.isdir(raw_directory): \n",
    "                    os.makedirs(raw_directory)\n",
    "                visual_directory = os.path.join(SAVE_DIR, 'visual',\n",
    "                                               obj_details['obj_name'])\n",
    "                if not os.path.isdir(visual_directory): \n",
    "                    os.makedirs(visual_directory)\n",
    "\n",
    "                cv2.imwrite(os.path.join(img_directory,\n",
    "                                        _IMAGE_FORMAT % (img_number+1) + '.jpg'), \n",
    "                            augmented_image)\n",
    "                cv2.imwrite(os.path.join(raw_directory,\n",
    "                                        _RAW_FORMAT % (img_number+1) + '.png'), \n",
    "                            augmented_label)\n",
    "                cv2.imwrite(os.path.join(visual_directory, \n",
    "                                        _VISUAL_FORMAT % (img_number+1) + '.jpg'), \n",
    "                            self.get_visual_image(augmented_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_def = {'f20_20_B': 1, 's40_40_B': 2, 'f20_20_G': 3, 's40_40_G': 4,  'm20_100': 5, \n",
    "             'm20': 6, 'm30': 7, 'r20': 8, 'bearing_box_ax01': 9, 'bearing': 10, 'axis': 11, \n",
    "             'distance_tube': 12, 'motor': 13, 'container_box_blue': 14, 'container_box_red': 15, \n",
    "             'bearing_box_ax16': 16, 'em_01': 17, 'em_02': 18, 'background': 19}\n",
    "\n",
    "b_it_bots_dataset = B_it_bots_Segmentation_Dataset(label_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_it_bots_dataset.perform_augmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add blur, flip, rotation...\n",
    "# allow more number of images..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
