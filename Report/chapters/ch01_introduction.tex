%!TEX root = ../report.tex

\chapter{Introduction}

In recent years, deep learning has significantly impacted research in the field of computer vision. Variations of Convolutional Neural Network architectures have shown state-of-the-art performance in computer vision tasks such as image classification \cite{DBLP:journals/corr/HeZRS15}, object detection \cite{DBLP:journals/corr/RedmonDGF15}, action recognition \cite{DBLP:journals/corr/SimonyanZ14} and semantic segmentation \cite{DBLP:journals/corr/abs-1802-02611}. A considerable part of this success comes from the supervised learning paradigm through which the networks are trained with labeled samples.

State-of-the-art deep learning techniques in semantic segmentation also make use of the supervised learning paradigm. Semantic segmentation is treated as a pixelwise classification problem with the goal of assigning a class from a list of desired classes to every pixel in an image. The resultant image splits objects of interest into different regions thereby achieving the intended segmentation into meaningful regions.

	\begin{figure}
		\centering
		\begin{subfigure}{.4\textwidth}
			\centering
			\includegraphics[width=1\linewidth]{images/classification}
			\caption{}
			\label{Fig:cls}
		\end{subfigure}
		\begin{subfigure}{.4\textwidth}
			\centering
			\includegraphics[width=1\linewidth]{images/segmentation}
			\caption{}
			\label{Fig:seg}
		\end{subfigure}
		\caption{(a) In image classification, we just get the output "em\_01". (b) In semantic segmentation, we get an output image with each pixel labeled from which we can infer that the image consists of "em\_01" and "background".}
		\label{Fig:clsseg}
	\end{figure}
	
Unlike the task of image classification (Figure \ref{Fig:cls}), where the location and boundaries of the desired object in the image is irrelevant, semantic segmentation (Figure \ref{Fig:seg}) requires the neural network to be able to spatially localize desired objects, delineate object boundaries and produce single channel segmentation map (output image) which is of the same size as the input image.

\section{Motivation}

Semantic segmentation provides rich information from image space which could be interpreted to make useful inferences about the real world scene depicted by the image. We look at three potential applications of sematic segmentation which stand out to show the benefits of information obtained through semantic segmentation. 

\subsection{Potential applications}

Semantic segmentation can be used in autonomous cars to segment a road scene and extract information such as where the road is, where pedestrains are and so on. An example street scene segmentation is shown in Figure \ref{Fig:appauto}. In robotics, an example application would be segmentation of an indoor dining table shown in Figure \ref{Fig:approbo}. A robot could use this information to indentify plates, chairs and so on. In augmented reality, an augmented dog could be placed in a sidewalk to walk a person to his destination as illustrated in Figure \ref{Fig:appaug}. 

	\begin{figure}
		\centering
		\begin{subfigure}{.3\textwidth}
			\centering
			\includegraphics[width=.95\linewidth]{images/auto_driving}
			\caption{}
			\label{Fig:appauto}
		\end{subfigure}
		\begin{subfigure}{.3\textwidth}
			\centering
			\includegraphics[width=.8\linewidth]{images/indoor}
			\caption{}
			\label{Fig:approbo}
		\end{subfigure}
		\begin{subfigure}{.3\textwidth}
			\centering
			\includegraphics[width=.8\linewidth]{images/vr_dog}
			\caption{}
			\label{Fig:appaug}
		\end{subfigure}
		\caption{(a) Street scene \cite{cityscapes}, (b) Indoor environment \cite{indoor}, (c) Augmented guide \cite{techcrunch}.}
		\label{Fig:app}
	\end{figure}


\section{Challenges and Difficulties}

In this section we look at the difficulties posed by semantic segmentation in a deep learning setting.

\subsection{Labeling cost}

As semantic segmentation is a pixelwise classification task, every pixel in the ground truth image needs to be labeled. This can be achieved by first performing accurate object boundary delineation and later annotate each region with the corresponding class. Since objects could have a variety of shapes, this boundary delineation becomes difficult. Object occlusions and image space cluttered with objects further adds to this difficulty.

\subsection{Context knowledge}

An image can be seen interms of a local or a global context. 

	\begin{figure}
		\centering
		\begin{subfigure}{.4\textwidth}
			\centering
			\includegraphics[width=.9\linewidth]{images/em_01_context_l}
			\caption{}
			\label{Fig:em01l}
		\end{subfigure}
		\begin{subfigure}{.4\textwidth}
			\centering
			\includegraphics[width=.9\linewidth]{images/motor_context_l}
			\caption{}
			\label{Fig:em01l}
		\end{subfigure}
		\begin{subfigure}{.4\textwidth}
			\centering
			\includegraphics[width=.9\linewidth]{images/em_01_context_g}
			\caption{}
			\label{Fig:em01g}
		\end{subfigure}
		\begin{subfigure}{.4\textwidth}
			\centering
			\includegraphics[width=.9\linewidth]{images/motor_context_g}
			\caption{}
			\label{Fig:motorg}
		\end{subfigure}
		\caption{Illustration of a local region in (a) "em\_01" and (b) "motor". The two local regions provide local context. Illustration of region containing entire object shown in (c) "em\_01" and (d) "motor". The regions illustrated in (c) and (d) can be said to provide global context of corresponding objects.}
		\label{Fig:context}
	\end{figure}

\subsection{Model complexity}



\section{Problem Statement}

