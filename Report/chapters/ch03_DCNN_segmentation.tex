%!TEX root = ../report.tex

\chapter{DCNN and Semantic Segmentation}

	In this chapter, we look into the basic concepts of neural networks and later, how such concepts have been used for the task of semantic segmentation. In section  \textbf{[todo]}

\section{Artificial Neural Networks}

Artificial Neural Networks (ANN), inspired by the neural networks in our brain, was designed to learn tasks without explicitly programming descriptive features of the concerned tasks. An ANN is made up of processing units called neurons which performs a non-linear transformation, using an activation function, of the weighted linear combination of inputs.  Many such neurons are connected to one another in an ANN resulting in its ability to learn highly non-linear function mappings from input to output space. 


\subsection{Multilayer Perceptron}

The Multilayer Perceptron (MLP) is a feedforward neural network with at least one layer in addition to an input and an output layer. The additional layers lie in between the input and the output layers and are called hidden layers. The input layer 

\section{Convolutional Neural Networks}

Convolutional Neural Networks (CNNs or Conv Nets) are a class of feedforward neural networks which are used in the field of computer vision. Tasks such as image classification, object detection and semantic segmentation make use of CNNs. CNNs are based on the convolution operation which is 

\subsection{Covolution theorem}

\subsection{CNN Architecture}

\subsubsection{Convolutional layer}

\subsubsection{Pooling layer}

\subsubsection{Activation layer}

\subsubsection{Batch normalization layer}

\subsubsection{Fully-connected layer}

\section{Deep Learning for Semantic Segmentation}

